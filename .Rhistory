#Find all state names that start with "South" and end with "na"
x[str_detect(x, "^South+na$")]
#Find all state names that start with "South" and end with "na"
x[str_detect(x, "^South | na$")]
x <- c("4044132000", "520-123-2000", "844.999.4500", "(400) 123-4567", "10/30/2017", "100,000,000")p
hone_number_regex_str = "your regex string goes here"
str_detect(x, phone_number_regex_str)
x <- c("4044132000", "520-123-2000", "844.999.4500", "(400) 123-4567", "10/30/2017", "100,000,000")p
hone_number_regex_str = "/^[+]?(\d{1,2})"
str_detect(x, phone_number_regex_str)
hone_number_regex_str = "(^| )[0-9.() -]{5,}( |$)"
str_detect(x, phone_number_regex_str)
phone_number_regex_str = "(^| )[0-9.() -]{5,}( |$)"
str_detect(x, phone_number_regex_str)
y <- c("4044132000", "520-123-2000", "844.999.4500", "(400) 123-4567", "10/30/2017", "100,000,000")
phone_number_regex_str = "(^| )[0-9.() -]{5,}( |$)"
str_detect(y, phone_number_regex_str)
regex_phonenumber = "\\d{3}\\[:punct:]?\\d{3}\\[:punct:]?\\d{4}"
str_detect(y, regex_phonenumber)
regex_phonenumber = "\\d{3}\\?[:punct:]?\\d{3}\?\[:punct:]?\\d{4}"
regex_phonenumber = "\\d{3}\\?[:punct:]?\\d{3}\\?[:punct:]?\\d{4}"
str_detect(y, regex_phonenumber)
regex_phonenumber = "\\d{3}\\d{3}\\d{4}"
str_detect(y, regex_phonenumber)
regex_phonenumber = "\\d{3}\\[:punct:]\\d{3}\\[:punct:]\\d{4}"
str_detect(y, regex_phonenumber)
regex_phonenumber = "[:punct:]?\\d{3}[:punct:]? ?\\d{3}[:punct:]\\d{4}"
str_detect(y, regex_phonenumber)
regex_phonenumber = "[:punct:]?\\d{3}[:punct:]? ?\\d{3}[:punct:]?\\d{4}"
str_detect(y, regex_phonenumber)
nstall.packages("tidytext")
install.packages("wordcloud")
install.packages("sentimentr")
install.packages(c("igraph", "ggforce", "ggraph"))
install.packages("topicmodels")
install.packages("broom")
install.packages("tictoc")
install.packages("spacyr")
library(stringr)
library(tidyverse)
install.packages("broom")
#Natural Language Processing
install.packages("tidytext")
getwd()
folder = "/Users/haonguyen/Desktop/CIS8393 - Using R/aclImdb"
fnames = list.files(folder, recursive = T) #get all filenames under aclImdb
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "/(neg|pos)/.+txt")]
ll = length(fnames)
ll
install.packages(c("foreach", "doParallel"))
library(foreach)
library(doParallel)
library(purrr)
library(foreach)
library(doParallel)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
walk(fnames[1:6], print)
walk(fnames[(ll-5):ll], print)
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
stopImplicitCluster() # stop the cluster if you don't need it anymore
walk(fnames[1:6], print)
walk(fnames[(ll-5):ll], print)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
folder = "/Users/haonguyen/Desktop/CIS8393 - Using R/aclImdb/test"
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
ll = length(fnames)
ll
walk(fnames[1:6], print)
walk(fnames[(ll-5):ll], print)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
stopImplicitCluster()
folder = "/Users/haonguyen/Desktop/CIS8393 - Using R/aclImdb/"
fnames = list.files(folder, recursive = T) #get all filenames under aclImdb
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
ll = length(fnames)
ll
walk(fnames[1:6], print)
walk(fnames[(ll-5):ll], print)
install.packages(c("foreach", "doParallel"))
library(purrr)
library(foreach)
library(doParallel)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
stopImplicitCluster() #
install.packages(c("foreach", "doParallel"))
setwd("/Users/haonguyen/Desktop/CIS8393 - Using R/")
folder = "aclImdb/"
fnames = list.files(folder, recursive = T) #get all filenames under aclImdb
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
ll = length(fnames)
ll
walk(fnames[1:6], print)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
stopImplicitCluster()
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
df
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
library(purrr)
library(foreach)
library(doParallel)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
library(tidytext)
library(stringr)
library(tidyverse)
setwd("/Users/haonguyen/Desktop/CIS8393 - Using R/")
folder = "aclImdb/"
fnames = list.files(folder, recursive = T) #get all filenames under aclImdb
#we are only interested in the txt files under the neg/pos folder
fnames=fnames[str_detect(fnames, "(neg|pos)/.+txt")]
ll = length(fnames)
ll
walk(fnames[1:6], print)
walk(fnames[(ll-5):ll], print)
#install.packages(c("foreach", "doParallel"))
library(purrr)
library(foreach)
library(doParallel)
n_core = parallel::detectCores()
registerDoParallel(n_core) #initiate a parallel cluster
# read files into R in parallel
txts = foreach(i = 1:length(fnames),
.combine = c, .packages = "tidyverse") %dopar% {
read_file(str_c(folder, fnames[i]))
}
stopImplicitCluster() # stop the cluster if you don't need it anymore
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
df
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
df = data_frame(fname = fnames, text = txts)
df
df = df %>%
separate(fname,
into=c("type", "polarity", "review_id", "rating", "ext"),
sep="/|_|\\.") %>%
arrange(review_id)
df
df = df %>%
mutate(doc_id = str_c(type, polarity, review_id, sep = "_")) %>%
mutate(text = str_replace_all(text, "(<br />)+", " "),
review_id = as.numeric(review_id),
rating = as.numeric(rating)) %>%
select(type, polarity, rating, review_id, doc_id, text)
df
library(tidytext)
tokens <- df %>%
unnest_tokens(output = word, input = text)
tokens
tokens %>%
count(word,
sort = TRUE)
sw = get_stopwords()
sw
cleaned_tokens <- tokens %>%
filter(!word %in% sw$word)
nums <- cleaned_tokens %>%
filter(str_detect(word, "^[0-9]")) %>%
select(word) %>% unique()
nums
cleaned_tokens <- cleaned_tokens %>%
filter(!word %in% nums$word)
length(unique(cleaned_tokens$word))
cleaned_tokens %>%
count(word, sort = T) %>%
rename(word_freq = n) %>%
ggplot(aes(x=word_freq)) +
geom_histogram(aes(y=..count..), color="black", fill="blue", alpha=0.3) +
scale_x_continuous(breaks=c(0:5,10,100,500,10e3),
trans="log1p", expand=c(0,0)) +
scale_y_continuous(breaks=c(0,100,1000,5e3,10e3,5e4,10e4,4e4), expand=c(0,0)) +
theme_bw()
rare <- cleaned_tokens %>%
count(word) %>%
filter(n<10) %>%
select(word) %>%
unique()
rare
cleaned_tokens <- cleaned_tokens %>%
filter(!word %in% rare$word)
length(unique(cleaned_tokens$word)
)
library(wordcloud)
# define a nice color palette
pal <- brewer.pal(8,"Dark2")
# plot the 100 most common words
cleaned_tokens %>%
count(word) %>%
with(wordcloud(word, n, random.order = FALSE, max.words = 100, colors=pal))
get_sentiments("nrc")
get_sentiments("afinn")
library(tidytext)
get_sentiments("nrc")
get_sentiments("afinn")
library(textdata)
install.packages("textdata")
library(textdata)
get_sentiments("nrc")
sent_reviews = cleaned_tokens %>%   left_join(get_sentiments("nrc")) %>%  rename(nrc = sentiment) %>%  left_join(get_sentiments("bing")) %>%  rename(bing = sentiment) %>%  left_join(get_sentiments("afinn")) %>%  rename(afinn = value)sent_reviews
sent_reviews = cleaned_tokens %>%   left_join(get_sentiments("nrc")) %>%  rename(nrc = sentiment) %>%  left_join(get_sentiments("bing")) %>%  rename(bing = sentiment) %>%  left_join(get_sentiments("afinn")) %>%  rename(afinn = value)sent_reviews
sent_reviews = cleaned_tokens %>%
left_join(get_sentiments("nrc")) %>%
rename(nrc = sentiment) %>%
left_join(get_sentiments("bing")) %>%
rename(bing = sentiment) %>%
left_join(get_sentiments("afinn")) %>%
rename(afinn = value)
sent_reviews = cleaned_tokens %>%
left_join(get_sentiments("nrc")) %>%
rename(nrc = sentiment) %>%
left_join(get_sentiments("bing")) %>%
rename(bing = sentiment) %>%
left_join(get_sentiments("afinn")) %>%
rename(afinn = value)
sent_reviews
bing_word_counts <- sent_reviews %>%
filter(!is.na(bing)) %>%
count(word, bing, sort = TRUE)
bing_word_counts
bing_word_counts %>%
filter(n > 10000) %>%
mutate(n = ifelse(bing == "negative", -n, n)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = bing)) +  geom_col() +  coord_flip() +  labs(y = "Contribution to sentiment")
ncr_word_counts <- sent_reviews %>%
filter(!is.na(ncr)) %>%
count(word, ncr, sort = TRUE)
ncr_word_counts
nrc_word_counts <- sent_reviews %>%
filter(!is.na(nrc)) %>%
count(word, ncr, sort = TRUE)
nrc_word_counts
nrc_word_counts <- sent_reviews %>%
filter(!is.na(nrc)) %>%
count(word, nrc, sort = TRUE)
nrc_word_counts
nrc_word_counts %>%
filter(n > 10000) %>%
mutate(n = ifelse(nrc == "negative", -n, n)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = nrc)) +  geom_col() +  coord_flip() +  labs(y = "Contribution to sentiment")
nrc_word_counts %>%
filter(!is.na(nrc)) %>%
ggplot(aes(word, n, fill = nrc)) +
geom_col() +
coord_flip() +
labs(y = "Contribution to sentiment")
nrc_word_counts %>%
filter(!is.na(nrc)) %>%
ggplot(aes(word, n, fill = nrc)) +
labs(y = "Contribution to sentiment")
nrc_word_counts %>%
filter(!is.na(nrc)) %>%
ggplot(.,aes(x = nrc)) +
geom_bar()
review_sentences <- df %>%
unnest_tokens(output = sentence, input = text, token = "sentences")
review_sentences
library(sentimentr)
sentiment('I am not very happy. He is very happy')
knitr::opts_chunk$set(echo = TRUE)
r <- reddit_urls(subreddit = "Coronavirus", page_threshold = 20)
library(RedditExtractoR)
library(tidyverse)
library(wordcloud)
library(tidytext)
library(recipes)
library(skimr)
library(h2o)
library(RCurl)
r <- reddit_urls(subreddit = "Coronavirus", page_threshold = 20)
rc <- reddit_content(r$URL)
rc_rel <- rc[c("comment", "comment_score", "post_score")]
rc_rel <- mutate(rc_rel, id = rownames(rc_rel))
rm(list = ls())
setwd("/Users/haonguyen/Documents/GitHub/BigDataAnalyticFinalProject")
# install.packages("class")
library(class)
# install.packages("e1071")
library(e1071)
library(lattice)
library(ggplot2)
library(caret)
# install.packages("DMwR")
library(DMwR)    # For KNN
# install.packages("ggvis")
library(ggvis)
library(dplyr)
library(randomForest)
# install.packages("devtools")
library(devtools)
#devtools::install_github('araastat/reprtree')
library(reprtree)
# install.packages("mlbench")
library(mlbench)
# install.packages("caret")
library(caret)
# install.packages("caretEnsemble")
library(caretEnsemble)
library(tidyverse)
library(h2o)
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
#To understand what is each column associated with what.
features<-read.table("./UCI HAR Dataset/features.txt")
df_activity <- y_train
df_activity <- df_activity %>%
mutate(Activity = case_when(V1 == 1 ~ 'WALKING',
V1 == 2 ~ 'WALKING_UPSTAIRS',
V1 == 3 ~ 'WALKING_DOWNSTAIRS',
V1 == 4 ~ 'SITTING',
V1 == 5 ~ 'STANDING',
V1 == 6 ~ 'LAYING'))
theme_set(theme_classic())
pie <- ggplot(df_activity, aes(x = "", fill = factor(Activity))) +
geom_bar(width = 1) +
theme(axis.line = element_blank(),
plot.title = element_text(hjust=0.5)) +
labs(fill="Activity",
x=NULL,
y=NULL,
title="Pie Chart of Activity - TRAINING",
caption="Source: y_train")
pie + coord_polar(theta = "y", start=0)
df_filtered_features <- features %>%
mutate(Col_Names = paste("V",features$V1, sep = "")) %>%
filter(str_detect(V2, pattern = "max()")) %>%
select(Col_Names, V2)
X_train_max <- X_train %>%
select(c(df_filtered_features$Col_Names))
ggplot(X_train_max, aes(x=(1:7352))) +
geom_point(mapping = aes(y = X_train_max$V10), color = 'blue') +
geom_point(mapping = aes(y = X_train_max$V11), color = 'black') +
geom_point(mapping = aes(y = X_train_max$V12), color = 'red') +
labs(x = "Observations",y="Values" , title="tBodyAcc-max()-XYZ value plot")
df_filtered_features_2 <- features %>%
mutate(Col_Names = paste("V",features$V1, sep = "")) %>%
filter(str_detect(V2, pattern = "angle()")) %>%
select(Col_Names, V2)
X_train_angle <- X_train %>%
select(c(df_filtered_features_2$Col_Names))
ggplot(X_train_angle, aes(x=(1:7352))) +
geom_point(mapping = aes(y = X_train_angle$V555), color = 'blue') +
geom_point(mapping = aes(y = X_train_angle$V556), color = 'black') +
geom_point(mapping = aes(y = X_train_angle$V557), color = 'red') +
geom_point(mapping = aes(y = X_train_angle$V558), color = 'green') +
geom_point(mapping = aes(y = X_train_angle$V559), color = 'magenta') +
geom_point(mapping = aes(y = X_train_angle$V560), color = 'yellow') +
labs(x = "Observations", y="Values" , title="angle() values plot")
source('~/Documents/GitHub/BigDataAnalyticFinalProject/FinalProject.R')
data.rf=randomForest(class_train ~ ., data=X_train, ntree=100, mtry=2, importance=TRUE)
rm(list = ls())
setwd("/Users/haonguyen/Documents/GitHub/BigDataAnalyticFinalProject")
# install.packages("class")
library(class)
# install.packages("e1071")
library(e1071)
library(lattice)
library(ggplot2)
library(caret)
# install.packages("DMwR")
library(DMwR)    # For KNN
# install.packages("ggvis")
library(ggvis)
library(dplyr)
library(randomForest)
# install.packages("devtools")
library(devtools)
#devtools::install_github('araastat/reprtree')
library(reprtree)
# install.packages("mlbench")
library(mlbench)
# install.packages("caret")
library(caret)
# install.packages("caretEnsemble")
library(caretEnsemble)
library(tidyverse)
library(h2o)
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
data.rf=randomForest(class_train ~ ., data=X_train, ntree=100, mtry=2, importance=TRUE)
data.rf #Confustion matrix
varImpPlot(data.rf)
class_train = as.factor(y_train[,1])
class_test = as.factor(y_test[,1])
#Change column name in label of training and testing
y.train <- as_tibble(y_train)
y.train = y.train %>%
rename(
y = V1
)
dim(y_train)
y.test <- as_tibble(y_test)
y.test = y.test %>%
rename(
y = V1
)
dim(y.test)
#Combine
train.df = data.frame(X_train, y.train)
valid.df = data.frame(X_test, y.test)
## Check null value
sum(is.na(train.df))
sum(is.na(valid.df))
data.rf=randomForest(class_train ~ ., data=X_train, ntree=100, mtry=2, importance=TRUE)
data.rf #Confustion matrix
varImpPlot(data.rf)
source('~/Documents/GitHub/BigDataAnalyticFinalProject/FinalProject.R')
#Check imbalance of data
hist(train.df$y)
df_activity <- y_train
df_activity <- df_activity %>%
mutate(Activity = case_when(V1 == 1 ~ 'WALKING',
V1 == 2 ~ 'WALKING_UPSTAIRS',
V1 == 3 ~ 'WALKING_DOWNSTAIRS',
V1 == 4 ~ 'SITTING',
V1 == 5 ~ 'STANDING',
V1 == 6 ~ 'LAYING'))
theme_set(theme_classic())
pie <- ggplot(df_activity, aes(x = "", fill = factor(Activity))) +
geom_bar(width = 1) +
theme(axis.line = element_blank(),
plot.title = element_text(hjust=0.5)) +
labs(fill="Activity",
x=NULL,
y=NULL,
title="Pie Chart of Activity - TRAINING",
caption="Source: y_train")
pie + coord_polar(theta = "y", start=0)
View(features)
knn5_pred <- knn(train = train.df, test = valid.df, cl = train.df$y, k=5)
#NROW(knn5_pred) # compare size with y_test
##Evaluation KNN_5
table(knn5_pred , valid.df$y)
confusionMatrix(table(knn5_pred , valid.df$y))
confusionMatrix(poly.pred.test, valid.df$y)
confusionMatrix(linear.pred.test, valid.df$y)
linear.pred.test <- predict(best.linear, newdata = valid.df)
confusionMatrix(linear.pred.test, valid.df$y)
